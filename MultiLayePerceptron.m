% K-Fold method applied on the data set
Fold_number=10; % Uses for K-Fold cross validation
% Data_set is a matrix of dimension [100*9] 
Data_set=[-0.33,0.69,0,1,1,0,0.8,0,0.88; -0.33,0.94,1,0,1,0,0.8,1,0.31; -0.33,0.5,1,0,0,0,1,-1,0.5; -0.33,0.75,0,1,1,0,1,-1,0.38; -0.33,0.67,1,1,0,0,0.8,-1,0.5; -0.33,0.67,1,0,1,0,0.8,0,0.5; -0.33,0.67,0,0,0,-1,0.8,-1,0.44; -0.33,1,1,1,1,0,0.6,-1,0.38; 1,0.64,0,0,1,0,0.8,-1,0.25; 1,0.61,1,0,0,0,1,-1,0.25; 1,0.67,1,1,0,-1,0.8,0,0.31; 1,0.78,1,1,1,0,0.6,0,0.13; 1,0.75,1,1,1,0,0.8,1,0.25; 1,0.81,1,0,0,0,1,-1,0.38; 1,0.94,1,1,1,0,0.2,-1,0.25; 1,0.81,1,1,0,0,1,1,0.5; 1,0.64,1,0,1,0,1,-1,0.38; 1,0.69,1,0,1,0,0.8,-1,0.25; 1,0.75,1,1,1,0,1,1,0.25; 1,0.67,1,0,0,0,0.8,1,0.38; 1,0.67,0,0,1,0,0.8,-1,0.25; 1,0.75,1,0,0,0,0.6,0,0.25; 1,0.67,1,1,0,0,0.8,-1,0.25; 1,0.69,1,0,1,-1,1,-1,0.44; 1,0.56,1,0,1,0,1,-1,0.63; 1,0.67,1,0,0,0,1,-1,0.25; 1,0.67,1,0,1,0,0.6,-1,0.38; 1,0.78,1,1,0,1,0.6,-1,0.38; 1,0.58,0,0,1,0,1,-1,0.19; 1,0.67,0,0,1,0,0.6,0,0.5; 1,0.61,1,0,1,0,1,-1,0.63; 1,0.56,1,0,0,0,1,-1,0.44; 1,0.64,0,0,0,0,1,-1,0.63; 1,0.58,1,1,1,0,0.8,0,0.44; 1,0.56,1,1,1,0,1,-1,0.63; -1,0.78,1,1,0,1,0.6,-1,0.38; -1,0.78,1,0,1,0,1,-1,0.25; -1,0.56,1,0,1,0,1,-1,0.63; -1,0.67,0,0,1,0,0.6,0,0.5; -1,0.69,1,0,0,0,1,-1,0.31; -1,0.53,1,1,1,0,0.8,1,0.5; -1,0.56,1,1,0,0,0.8,1,0.5; -1,0.58,1,0,1,-1,0.8,1,0.5; -1,0.56,1,0,0,0,1,-1,0.44; -1,0.53,1,1,0,1,1,0,0.31; -1,0.53,1,0,0,1,1,0,0.44; -0.33,0.56,1,0,0,0,1,-1,0.63; -0.33,0.72,1,1,0,0,0.6,1,0.19; -0.33,0.64,1,1,1,0,0.8,-1,0.31; -0.33,0.75,1,1,1,0,0.6,-1,0.19; -0.33,0.67,1,0,1,0,0.8,-1,0.19; -0.33,0.53,1,1,0,1,1,-1,0.75; -0.33,0.53,1,1,0,0,0.8,0,0.5; -0.33,0.58,1,1,1,-1,0.8,0,0.19; -0.33,0.61,1,0,1,0,1,-1,0.63; -0.33,0.58,1,0,1,0,0.8,1,0.19; -0.33,0.53,1,1,0,0,0.8,0,0.75; -0.33,0.69,1,1,1,-1,1,-1,0.75; -0.33,0.56,1,1,0,0,0.4,1,0.63; 1,0.58,0,0,0,1,0.8,1,0.44; 1,0.56,0,0,0,1,0.8,0,1; -1,0.64,1,0,0,1,1,1,0.25; -1,0.61,1,1,1,0,0.6,-1,0.38; -1,0.56,1,0,0,1,1,-1,0.5; -1,0.53,1,0,0,1,0.8,-1,0.31; -0.33,0.56,0,0,1,0,1,-1,0.56; -0.33,0.5,1,1,0,-1,0.8,0,0.88; -0.33,0.5,1,0,0,1,1,-1,0.47; -0.33,0.5,1,0,0,1,0.8,0,0.31; -0.33,0.5,1,0,1,-1,0.8,-1,0.5; -0.33,0.5,1,1,0,-1,0.8,0,0.88; 0.33,0.69,1,0,0,1,1,-1,0.31; 1,0.56,1,0,0,1,0.6,0,0.5; -1,0.5,1,0,0,1,0.8,-1,0.44; -1,0.53,1,0,0,1,0.8,-1,0.63; -1,0.78,1,0,1,1,1,1,0.25; -1,0.75,1,0,1,1,0.6,0,0.56; -1,0.72,1,1,1,1,0.8,-1,0.19; -1,0.53,1,1,0,1,0.8,-1,0.38; -1,1,1,0,1,1,0.6,0,0.25; -0.33,0.92,1,1,0,1,1,-1,0.63; -1,0.81,1,1,1,1,0.8,0,0.19; -0.33,0.92,1,0,0,1,0.6,-1,0.19; -0.33,0.86,1,1,1,1,1,-1,0.25; -0.33,0.78,1,0,0,1,1,1,0.06; -0.33,0.89,1,1,0,0,0.6,1,0.31; -0.33,0.75,1,1,1,0,0.6,1,0.25; -0.33,0.75,1,1,1,1,0.8,1,0.25; -0.33,0.83,1,1,1,0,1,-1,0.31; -0.33,0.81,1,1,1,0,1,1,0.38; -0.33,0.81,1,1,1,1,0.8,-1,0.38; 0.33,0.78,1,0,0,0,1,1,0.06; 0.33,0.75,1,1,0,0,0.8,-1,0.38; 0.33,0.75,1,0,1,0,0.8,-1,0.44; 1,0.58,1,0,0,0,0.6,1,0.5; -1,0.67,1,0,0,0,1,-1,0.5; -1,0.61,1,0,0,0,0.8,0,0.5; -1,0.67,1,1,1,0,1,-1,0.31; -1,0.64,1,0,1,0,1,0,0.19; -1,0.69,0,1,1,0,0.6,-1,0.19];
Target=[0 1;1 0;0 1;0 1;1 0;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;1 0;0 1;1 0;0 1;0 1;0 1;1 0;0 1;0 1;1 0;1 0;0 1;1 0;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;1 0;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;1 0;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;1 0;0 1;0 1;0 1;0 1;0 1;0 1;0 1;0 1;1 0;0 1;0 1;0 1;0 1;0 1;0 1];
% Fold_index is generated by using crossvalind() function in matlab
Fold_index=[3;10;10;5;9;3;8;9;4;10;2;6;9;10;2;4;4;8;2;3;2;6;7;6;6;9;2;8;10;6;5;8;4;9;3;5;5;1;2;4;7;2;2;3;6;5;10;8;1;7;4;7;5;2;9;10;1;3;3;7;9;7;9;7;10;8;3;7;1;5;8;9;1;1;10;7;4;4;8;1;6;6;5;4;10;6;1;5;6;8;3;9;8;5;3;1;7;1;2;4];
test_set=zeros(10, 9); % Initializes a matrix with zero values for elements
train_set=zeros(90,9);
train_target=zeros(90,2);
test_target=zeros(10,2);
count_t=1;
count_s=1;
for i = 1 : 100 %Creation of train_set and test_set
	if Fold_index(i)==Fold_number
		for n = 1 : 9
			test_set(count_t,n)=Data_set(i,n);
		end
		test_target(count_t,1)=Target(i,1);
		test_target(count_t,2)=Target(i,2);
		count_t=count_t + 1;
	else
		for n = 1 : 9
			train_set(count_s,n)=Data_set(i,n);
		end
		train_target(count_s,1)=Target(i,1);
		train_target(count_s,2)=Target(i,2);
		count_s=count_s + 1;
	end
end

numOf_epochs=2000; % Number of iterations
hidden_Layer_neurons=6;
output_Layer_neurons=2;
bias_hidden_layer=rand(hidden_Layer_neurons,1)*2-1;
bias_output_layer=rand(output_Layer_neurons,1)*2-1;
Weights_hidden_layer =rand(9,hidden_Layer_neurons,1)*2-1;
Weights_output_layer =rand(hidden_Layer_neurons,output_Layer_neurons)*2-1;
% Training Phase
for i =1 : numOf_epochs
	learning_rate= 0.5;
	for m = 1 : 90
		% Forward pass
		% Activation of the hidden units
		M=mod(i,100);
		if M==0
			learning_rate=learning_rate/2;
		end
		net_hidden = bias_hidden_layer;
		output_hidden_layer=zeros(hidden_Layer_neurons, 1);
		for j = 1 : hidden_Layer_neurons
			for k = 1 : 9;
				net_hidden(j)= net_hidden(j)+ Weights_hidden_layer(k,j)*train_set(m,k);
			end
			output_hidden_layer(j)=1/(1+exp(-1*net_hidden(j)));
		end
		% Activation of the output units
		net_output= bias_output_layer;
		output_final_layer=zeros(output_Layer_neurons, 1);
		for j = 1 : output_Layer_neurons
			for k =1 : hidden_Layer_neurons
				net_output(j)= net_output(j)+ Weights_output_layer(k,j)*output_hidden_layer(k);
			end	
			output_final_layer(j)=1/(1+exp(-1*net_output(j)));
		end
		%Backward pass
		% Calculating the output errors
		delta_output_layer=zeros(output_Layer_neurons,1);
		for j = 1 : output_Layer_neurons
			delta_output_layer(j)=(train_target(m,j)-output_final_layer(j))*output_final_layer(j)*(1-output_final_layer(j));
		end
		% Updating weights for output layer
		for j = 1 : hidden_Layer_neurons
			for k = 1 : output_Layer_neurons
				Weights_output_layer(j,k) = Weights_output_layer(j,k) + learning_rate*delta_output_layer(k)*output_hidden_layer(j);
			end
		
		end
		% Updating biases for output layer neurons
		for k = 1 : output_Layer_neurons
			bias_output_layer(k) = bias_output_layer(k)+ learning_rate*delta_output_layer(k);
		end
		% Calculating the errors of the hidden units
		delta_hidden_layer=zeros(hidden_Layer_neurons,1);
		for j = 1 : hidden_Layer_neurons
			s=0;
			for k = 1:output_Layer_neurons
				s=s+Weights_output_layer(j,k)*delta_output_layer(k);
			end
			delta_hidden_layer(j)= output_hidden_layer(j)*(1-output_hidden_layer(j))*s;
		end
		% Updating weights for hidden layer
		for j = 1 : 9
			for k = 1 : hidden_Layer_neurons
				Weights_hidden_layer(j,k) = Weights_hidden_layer(j,k) + learning_rate*delta_hidden_layer(k)*train_set(m,j);
			end
		
		end
		% Updating biases for hidden layer neurons
		for k = 1 : hidden_Layer_neurons
			bias_hidden_layer(k) = bias_hidden_layer(k)+ learning_rate*delta_hidden_layer(k);
		end
		
	end 

	
end
%-----------------------------------------------------------------------------------------------
% Testing Phase
Error=0;
for i = 1 : 10
	net_hidden = bias_hidden_layer;
	output_hidden_layer=zeros(hidden_Layer_neurons, 1);
	for j = 1 : hidden_Layer_neurons
		for k = 1 : 9;
			net_hidden(j)= net_hidden(j)+ Weights_hidden_layer(k,j)*test_set(i,k);% correct test_set later
		end
		output_hidden_layer(j)=1/(1+exp(-1*net_hidden(j)));
	end
	net_output= bias_output_layer;
	output_final_layer=zeros(output_Layer_neurons, 1);
	for j = 1 : output_Layer_neurons
		for k =1 : hidden_Layer_neurons
			net_output(j)= net_output(j)+ Weights_output_layer(k,j)*output_hidden_layer(k);
		end	
		output_final_layer(j)=1/(1+exp(-1*net_output(j)));
    end
	sum=0;
	for k = 1 : output_Layer_neurons
		t1=(test_target(i,k)-output_final_layer(k));
		sum=sum+(t1^2);
	end
	Error=Error+(sum)/2;
end
Error=Error/10;
fprintf('\n The error for fold %d is : %f \n',Fold_number ,Error);


